train_data <- train %>% filter(fold != i)
#creates vector of classes for both data sets
cl_train <- train_data$species
cl_test <- test_data$species
#removes class and fold columns from datasets
train_data <- train_data[ ,3:ncol(train_data)-1]
test_data <- test_data[ ,3:ncol(test_data)-1]
#stores predictions in dataset
class[train$fold == i] <- knn(train_data,
test_data,
cl_train,
k = k_nn,
prob = TRUE)
#creates vector to store misclassifications
error <- rep(NA, nrow(test_data))
#labels misclassifications
for (j in 1:nrow(test_data)) {
error[train$fold == j] =
(as.numeric(train$species[train$fold == j])) != class[train$fold == j]
}
#calculates misclassification rate
misclass_rate[i] <- sum(na.omit(as.numeric(error[train$fold == i])))
misclass_rate[i] <- misclass_rate[i] / length(cl_test)
}
#calculates mean misclassification rate
cv_err <- mean(misclass_rate)
#creates list of objects to return
my_list <- list()
my_list$cv_err <- cv_err
my_list$class <- class
#returns list
return(my_list)
}
#tests function
knn_1 <- my_knn_cv(train, cl, 1, 5)
knn_5 <- my_knn_cv(train, cl, 5, 5)
training_err_1 <- mean((knn_1$class - as.numeric(penguins$species))^2)
training_err_5 <- mean((knn_5$class - as.numeric(penguins$species))^2)
my_data <- data.frame("k_nn" = c(1,5),
"Misclassification Error" = c(knn_1$cv_err, knn_5$cv_err),
"Training Error" = c(training_err_1, training_err_5))
library(knitr)
library(kableExtra)
kable_styling(kable(my_data))
library(tidyverse)
library(randomForest)
my_data <- train
my_rf_cv <- function(k){
#creates vector to store cross validation errors
cv_errors_2 <- rep(NA, k)
#gives each observation a fold
my_data$fold <- sample(rep(1:k, length = nrow(my_data)))
for (i in 1:k) {
#creates training data out of data not in ith fold
data_train <- my_data %>% filter(fold != i)
data_test <- my_data %>% filter(fold == i)
#creates model with randomForest()
my_model <- randomForest(
body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm,
data = data_train,
ntree = 100
)
#creates vector of predictions
predictions_2 <- predict(my_model, data_test[, -1])
cv_errors_2[i] <- mean((predictions_2 - data_test$body_mass_g)^2)
}
#returns mean standard error
return(mean(cv_errors_2))
}
cv_mse <- my_rf_cv(5)
library(class)
library(tidyverse)
#removes observations with na values
penguins <- na.omit(penguins)
#removes unnecessary columns from dataset
train <- penguins
train$island <- NULL
train$sex <- NULL
train$year <- NULL
#creates function
my_knn_cv <- function(train, cl, k_nn, k_cv){
#randomly assigns observations to folds
train$fold <- sample(rep(1:k_cv, length = nrow(train)))
fold <- train$fold
#creates column to store prediction for all observations
class <- rep(NA, nrow(train))
#creates vector to store error calculations
misclass_rate <- rep(NA, k_cv)
#uses for loop to repeat steps for each fold
for (i in 1:k_cv) {
#creates train and test data
test_data <- train %>% filter(fold == i)
train_data <- train %>% filter(fold != i)
#creates vector of classes for both data sets
cl_train <- train_data$species
cl_test <- test_data$species
#removes class and fold columns from datasets
train_data <- train_data[ ,3:ncol(train_data)-1]
test_data <- test_data[ ,3:ncol(test_data)-1]
#stores predictions in dataset
class[train$fold == i] <- knn(train_data,
test_data,
cl_train,
k = k_nn,
prob = TRUE)
#creates vector to store misclassifications
error <- rep(NA, nrow(test_data))
#labels misclassifications
for (j in 1:nrow(test_data)) {
error[train$fold == j] =
(as.numeric(train$species[train$fold == j])) != class[train$fold == j]
}
#calculates misclassification rate
misclass_rate[i] <- sum(na.omit(as.numeric(error[train$fold == i])))
misclass_rate[i] <- misclass_rate[i] / length(cl_test)
}
#calculates mean misclassification rate
cv_err <- mean(misclass_rate)
#creates list of objects to return
my_list <- list()
my_list$cv_err <- cv_err
my_list$class <- class
#returns list
return(my_list)
}
#tests function
knn_1 <- my_knn_cv(train, cl, 1, 5)
knn_5 <- my_knn_cv(train, cl, 5, 5)
training_err_1 <- mean((knn_1$class - as.numeric(penguins$species))^2)
training_err_5 <- mean((knn_5$class - as.numeric(penguins$species))^2)
my_data <- data.frame("k_nn" = c(1,5),
"Misclassification Error" = c(knn_1$cv_err, knn_5$cv_err),
"Training Error" = c(training_err_1, training_err_5))
library(knitr)
library(kableExtra)
kable_styling(kable(my_data))
summary(lm(lifeExp ~ gdpPercap + continent, my_gapminder))
formula = lifeExp ~ gdpPercap + continent
data <- my_gapminder
formula <- lifeExp ~ gdpPercap + continent
model_frame <- model.frame(formula, data)
x <- model.matrix(formula, data = data)
y <- model.response(model_frame)
beta <- solve(t(x) %*% x) %*% t(x) %*% y
df <- nrow(data) - ncol(model_frame)
sigma_2 <- sum(((y - x %*% beta) ^ 2) / df)
my_solve <- sigma_2 * solve((t(x) %*% x))
my_solve
my_vector <- my_gapminder$gdpPercap
my_vector
my_vector <- my_gapminder$continent
my_vector
library(STAT302Package)
data("my_gapminder")
data("my_penguins")
fitted(my_lm(lifeExp ~ gdpPercap + continent, my_gapminder))
ggplot(my_gapminder$lifeExp, aes(x = fitted, y = actual)) +
geom_point()
ggplot(my_gapminder, aes(x = fitted, y = actual)) +
geom_point()
lm(lifeExp ~ gdpPercap + continent, my_gapminder)
#Creates data frame of actual and fitted values
mod_fits <- fitted(my_lm)
#Creates data frame of actual and fitted values
mod_fits <- fitted(my_lm(lifeExp ~ gdpPercap + continent, my_gapminder))
#Creates data frame of actual and fitted values
mod_fits <- fitted(lm(lifeExp ~ gdpPercap + continent, my_gapminder))
my_df <- data.frame(actual = my_gapminder$lifeExp, fitted = mod_fits)
#Plots actual vs. fitted graph
ggplot(my_df, aes(x = fitted, y = actual)) +
geom_point() +
geom_abline(slope = 1, intercept = 0, col = "red", lty = 2) +
theme_bw(base_size = 15) +
labs(x = "Fitted values", y = "Actual values", title = "Actual vs. Fitted") +
theme(plot.title = element_text(hjust = 0.5))
devtools::check()
devtools::document()
rm(list = c("data", "my_knn_cv", "my_rf_cv"))
devtools::document()
devtools::check()
devtools::check()
devtools::check()
my_rf_cv(5)
library(tidyverse)
library(randomForest)
my_data <- train
library(palmerpenguins)
data(package = "palmerpenguins")
data(penguins)
library(class)
library(tidyverse)
#removes observations with na values
penguins <- na.omit(penguins)
#removes unnecessary columns from dataset
train <- penguins
train$island <- NULL
train$sex <- NULL
train$year <- NULL
#creates function
my_knn_cv <- function(train, cl, k_nn, k_cv){
#randomly assigns observations to folds
train$fold <- sample(rep(1:k_cv, length = nrow(train)))
fold <- train$fold
#creates column to store prediction for all observations
class <- rep(NA, nrow(train))
#creates vector to store error calculations
misclass_rate <- rep(NA, k_cv)
#uses for loop to repeat steps for each fold
for (i in 1:k_cv) {
#creates train and test data
test_data <- train %>% filter(fold == i)
train_data <- train %>% filter(fold != i)
#creates vector of classes for both data sets
cl_train <- train_data$species
cl_test <- test_data$species
#removes class and fold columns from datasets
train_data <- train_data[ ,3:ncol(train_data)-1]
test_data <- test_data[ ,3:ncol(test_data)-1]
#stores predictions in dataset
class[train$fold == i] <- knn(train_data,
test_data,
cl_train,
k = k_nn,
prob = TRUE)
#creates vector to store misclassifications
error <- rep(NA, nrow(test_data))
#labels misclassifications
for (j in 1:nrow(test_data)) {
error[train$fold == j] =
(as.numeric(train$species[train$fold == j])) != class[train$fold == j]
}
#calculates misclassification rate
misclass_rate[i] <- sum(na.omit(as.numeric(error[train$fold == i])))
misclass_rate[i] <- misclass_rate[i] / length(cl_test)
}
#calculates mean misclassification rate
cv_err <- mean(misclass_rate)
#creates list of objects to return
my_list <- list()
my_list$cv_err <- cv_err
my_list$class <- class
#returns list
return(my_list)
}
#tests function
knn_1 <- my_knn_cv(train, cl, 1, 5)
knn_5 <- my_knn_cv(train, cl, 5, 5)
training_err_1 <- mean((knn_1$class - as.numeric(penguins$species))^2)
training_err_5 <- mean((knn_5$class - as.numeric(penguins$species))^2)
my_data <- data.frame("k_nn" = c(1,5),
"Misclassification Error" = c(knn_1$cv_err, knn_5$cv_err),
"Training Error" = c(training_err_1, training_err_5))
library(knitr)
library(kableExtra)
kable_styling(kable(my_data))
library(tidyverse)
library(randomForest)
my_data <- train
my_rf_cv <- function(k){
#creates vector to store cross validation errors
cv_errors_2 <- rep(NA, k)
#gives each observation a fold
my_data$fold <- sample(rep(1:k, length = nrow(my_data)))
for (i in 1:k) {
#creates training data out of data not in ith fold
data_train <- my_data %>% filter(fold != i)
data_test <- my_data %>% filter(fold == i)
#creates model with randomForest()
my_model <- randomForest(
body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm,
data = data_train,
ntree = 100
)
#creates vector of predictions
predictions_2 <- predict(my_model, data_test[, -1])
cv_errors_2[i] <- mean((predictions_2 - data_test$body_mass_g)^2)
}
#returns mean standard error
return(mean(cv_errors_2))
}
cv_mse <- my_rf_cv(5)
library(tidyverse)
library(randomForest)
my_data <- train
k <- 5
cv_errors_2 <- rep(NA, k)
my_data$fold <- sample(rep(1:k, length = nrow(my_data)))
View(my_data)
my_rf_cv
my_rf_cv(5)
my_rf_cv(5)
my_data <- na.omit(my_penguins)
my_rf_cv
my_rf_cv(5)
my_rf_cv()
my_rf_cv(5)
my_rf_cv(5)
my_rf_cv(5)
my_rf_cv(5)
my_data <- data(my_penguins, envir = environment())
my_data <- na.omit(my_data)
my_rf_cv(5)
my_data <- data("my_penguins", envir = environment())
my_data <- my_penguins
data(my_penguins, envir = environment())
data(my_penguins, envir = environment())
my_rf_cv(5)
my_data <- my_penguins
my_rf_cv(5)
my_rf_cv(5)
my_rf_cv(5)
library(STAT302Package)
my_rf_cv(5)
my_rf_cv(5)
my_data <- na.omit(my_penguins)
sample(rep(1:k, length = nrow(my_data)))
sample(rep(1:5, length = nrow(my_data)))
fold <- sample(rep(1:k, length = nrow(my_data)))
fold <- sample(rep(1:5, length = nrow(my_data)))
View(my_data)
fold <- as.data.frame(sample(rep(1:5, length = nrow(my_data))))
my_data$fold <- fold
View(my_data)
my_data <- na.omit(my_penguins)
fold <- as.data.frame(sample(rep(1:k, length = nrow(my_data))))
View(fold)
fold <- sample(rep(1:k, length = nrow(my_data)))
fold <- sample(rep(1:5, length = nrow(my_data)))
my_data$fold <- fold
View(my_data)
my_rf_cv(5)
my_data <- na.omit(my_penguins)
my_rf_cv(5)
my_data <- na.omit(my_penguins)
fold <- sample(rep(1:k, length = nrow(my_data)))
fold <- sample(rep(1:5, length = nrow(my_data)))
my_data <- cbind(my_data, fold)
View(my_data)
my_rf_cv(5)
library(STAT302Package)
my_rf_cv(5)
library(STAT302Package)
my_rf_cv(5)
library(STAT302Package)
library(ggplot2)
data("my_gapminder")
data("my_penguins")
my_rf_cv(5)
my_rf_cv(5)
k <- 5
data(my_penguins, envir = environment())
my_data <- na.omit(my_penguins)
cv_errors_2 <- rep(NA, k)
fold <- sample(rep(1:k, length = nrow(my_data)))
my_data <- cbind(my_data, fold)
for (i in 1:k) {
#creates training data out of data not in ith fold
data_train <- my_data %>% filter(fold != i)
data_test <- my_data %>% filter(fold == i)
#creates model with randomForest()
my_model <- randomForest(
body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm,
data = data_train,
ntree = 100
)
#creates vector of predictions
predictions_2 <- predict(my_model, data_test[, -1])
cv_errors_2[i] <- mean((predictions_2 - data_test$body_mass_g)^2)
}
library(randomForest)
k <- 5
> data(my_penguins, envir = environment())
> my_data <- na.omit(my_penguins)
> cv_errors_2 <- rep(NA, k)
> fold <- sample(rep(1:k, length = nrow(my_data)))
> my_data <- cbind(my_data, fold)
> for (i in 1:k) {
+     #creates training data out of data not in ith fold
+     data_train <- my_data %>% filter(fold != i)
+     data_test <- my_data %>% filter(fold == i)
+     #creates model with randomForest()
+     my_model <- randomForest(
+         body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm,
+         data = data_train,
+         ntree = 100
+     )
+     #creates vector of predictions
+     predictions_2 <- predict(my_model, data_test[, -1])
+     cv_errors_2[i] <- mean((predictions_2 - data_test$body_mass_g)^2)
+ }
my_rf_cv <- function(k){
#removes nas from my_penguins
data(my_penguins, envir = environment())
my_data <- na.omit(my_penguins)
#creates vector to store cross validation errors
cv_errors_2 <- rep(NA, k)
#gives each observation a fold
fold <- sample(rep(1:k, length = nrow(my_data)))
my_data <- cbind(my_data, fold)
for (i in 1:k) {
#creates training data out of data not in ith fold
data_train <- my_data %>% filter(fold != i)
data_test <- my_data %>% filter(fold == i)
#creates model with randomForest()
my_model <- randomForest(
body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm,
data = data_train,
ntree = 100
)
#creates vector of predictions
predictions_2 <- predict(my_model, data_test[, -1])
cv_errors_2[i] <- mean((predictions_2 - data_test$body_mass_g)^2)
}
my_data <- na.omit(my_penguins)
#creates vector to store cross validation errors
cv_errors_2 <- rep(NA, k)
#gives each observation a fold
fold <- sample(rep(1:k, length = nrow(my_data)))
my_data <- cbind(my_data, fold)
for (i in 1:k) {
#creates training data out of data not in ith fold
data_train <- my_data %>% filter(fold != i)
data_test <- my_data %>% filter(fold == i)
#creates model with randomForest()
my_model <- randomForest(
body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm,
data = data_train,
ntree = 100
)
#creates vector of predictions
predictions_2 <- predict(my_model, data_test[, -1])
cv_errors_2[i] <- mean((predictions_2 - data_test$body_mass_g)^2)
}
my_rf_cv(5)
devtools::document()
devtools::check()
devtools::document()
devtools::check()
my_rf_cv(5)
my_rf_cv(5)
my_data <- na.omit(my_penguins)
fold <- sample(rep(1:k, length = nrow(my_data)))
fold <- sample(rep(1:5, length = nrow(my_data)))
my_data <- merge(my_data, fold)
View(my_data)
my_data <- na.omit(my_penguins)
my_data <- merge(my_data, fold, by = species)
my_data <- merge(my_data, fold, by = fold)
my_data <- merge(my_data, fold, by = 8)
my_data <- merge(my_data, fold, by = 9)
devtools::check()
my_rf_cv(5)
my_rf_cv(5)
devtools::document()
devtools::check()
devtools::document()
devtools::check()
#removes observations with na values
train <- na.omit(my_penguins)
#removes unnecessary columns from dataset
train$island <- NULL
train$sex <- NULL
train$year <- NULL
#tests function, iterating with k_nn values from 1 to 10
knn_1 <- my_knn_cv(train, cl, 1, 5)
knn_1
#removes observations with na values
train <- na.omit(my_penguins)
#removes unnecessary columns from dataset
train$island <- NULL
train$sex <- NULL
train$year <- NULL
#tests function, iterating with k_nn values from 1 to 10
for (i in i:10) {
knn_i <- my_knn_cv(train, cl, i, 5)
knn_i$cv_err
#calculates training error
mean((knn_i$class - as.numeric(train$species))^2)
}
#removes observations with na values
train <- na.omit(my_penguins)
#removes unnecessary columns from dataset
train$island <- NULL
train$sex <- NULL
train$year <- NULL
#tests function, iterating with k_nn values from 1 to 10
for (i in 1:10) {
knn_i <- my_knn_cv(train, cl, i, 5)
knn_i$cv_err
#calculates training error
mean((knn_i$class - as.numeric(train$species))^2)
}
devtools::document()
devtools::check()
devtools::check()
my_rf_cv(5)
library(STAT302Package)
my_rf_cv(5)
my_rf_cv(5)
my_rf_cv(5)
my_rf_cv(5)
my_rf_cv(5)
traceback()
browser()
my_rf_cv()
my_rf_cv(5)
browser()
my_rf_cv()
my_rf_cv(5)
my_rf_cv(5)
my_rf_cv()
my_rf_cv(5)
