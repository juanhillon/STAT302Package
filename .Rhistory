cl_train,
k = k_nn,
prob = TRUE)
#creates vector to store misclassifications
error <- rep(NA, nrow(test_data))
#labels misclassifications
for (j in 1:nrow(test_data)) {
error[train$fold == j] =
(as.numeric(train$species[train$fold == j])) != class[train$fold == j]
}
#calculates misclassification rate
misclass_rate[i] <- sum(na.omit(as.numeric(error[train$fold == i])))
misclass_rate[i] <- misclass_rate[i] / length(cl)
}
#calculates mean misclassification rate
cv_err <- mean(misclass_rate)
#converts species to numeric
train$species <- as.numeric(train$species)
#generates output class
output_class <- knn(train, train, train$species, k = k_nn, prob = TRUE)
#creates list of objects to return
my_list <- list()
my_list$cv_err <- cv_err
my_list$class <- output_class
#returns list
return(my_list)
}
#tests function
my_knn_cv(train, cl, 1, 5)
knn_1 <- my_knn_cv(train, cl, 1, 5)
knn_5 <- my_knn_cv(train, cl, 5, 5)
training_err_1 <- mean((knn_1$class - as.numeric(penguins$species))^2)
training_err_5 <- mean((knn_5$class - as.numeric(penguins$species))^2)
my_data <- data.frame("k_nn" = c(1,5),
"Misclassification Error" = c(knn_1$cv_err, knn_5$cv_err),
"Training Error" = c(training_err_1, training_err_5))
library(knitr)
library(kableExtra)
kable_styling(kable(my_data))
library(class)
library(tidyverse)
#removes observations with na values
penguins <- na.omit(penguins)
#removes unnecessary columns from dataset
train <- penguins
train$island <- NULL
train$sex <- NULL
train$year <- NULL
cl <- train$species
#creates function
my_knn_cv <- function(train, cl, k_nn, k_cv){
#randomly assigns observations to folds
train$fold <- sample(rep(1:k_cv, length = nrow(train)))
fold <- train$fold
#creates column to store prediction for all observations
class <- rep(NA, nrow(train))
#creates vector to store error calculations
misclass_rate <- rep(NA, k_cv)
#uses for loop to repeat steps for each fold
for (i in 1:k_cv) {
#creates train and test data
test_data <- train %>% filter(fold == i)
train_data <- train %>% filter(fold != i)
#creates vector of classes for both data sets
cl_train <- train_data$species
cl_test <- test_data$species
#removes class and fold columns from datasets
train_data <- train_data[ ,3:ncol(train_data)-1]
test_data <- test_data[ ,3:ncol(test_data)-1]
#stores predictions in dataset
class[train$fold == i] <- knn(train_data,
test_data,
cl_train,
k = k_nn,
prob = TRUE)
#creates vector to store misclassifications
error <- rep(NA, nrow(test_data))
#labels misclassifications
for (j in 1:nrow(test_data)) {
error[train$fold == j] =
(as.numeric(train$species[train$fold == j])) != class[train$fold == j]
}
#calculates misclassification rate
misclass_rate[i] <- sum(na.omit(as.numeric(error[train$fold == i])))
misclass_rate[i] <- misclass_rate[i] / length(cl)
}
#calculates mean misclassification rate
cv_err <- mean(misclass_rate)
#converts species to numeric
train$species <- as.numeric(train$species)
#generates output class
output_class <- knn(train, train, train$species, k = k_nn, prob = TRUE)
#creates list of objects to return
my_list <- list()
my_list$cv_err <- cv_err
my_list$class <- output_class
#returns list
return(my_list)
}
#tests function
my_knn_cv(train, cl, 1, 5)
knn_1 <- my_knn_cv(train, cl, 1, 5)
knn_5 <- my_knn_cv(train, cl, 5, 5)
training_err_1 <- mean((knn_1$class - as.numeric(train$species))^2)
training_err_5 <- mean((knn_5$class - as.numeric(train$species))^2)
my_data <- data.frame("k_nn" = c(1,5),
"Misclassification Error" = c(knn_1$cv_err, knn_5$cv_err),
"Training Error" = c(training_err_1, training_err_5))
library(knitr)
library(kableExtra)
kable_styling(kable(my_data))
mean((knn_1$class - as.numeric(train$species))^2)
#removes observations with na values
train <- na.omit(my_penguins)
#removes unnecessary columns from dataset
train$island <- NULL
train$sex <- NULL
train$year <- NULL
cl <- train$species
#creates vectors to store training and cv misclassification errors
train_err <- rep(NA, 10)
cv_misclass_err <- rep(NA, 10)
#tests function, iterating with k_nn values from 1 to 10
for (i in 1:10) {
knn_i <- my_knn_cv(train, cl, i, 5)
cv_misclass_err[i] <- knn_i$cv_err
#calculates training error
train_err[i] <- mean((knn_i$class - as.numeric(train$species))^2)
}
my_df <- data.frame("k_nn" = c(1:10),
"CV Misclassification Error" = cv_misclass_err,
"Training Error" = train_err)
kable_styling(kable(my_df))
library(class)
library(tidyverse)
#removes observations with na values
penguins <- na.omit(penguins)
#removes unnecessary columns from dataset
train <- penguins
train$island <- NULL
train$sex <- NULL
train$year <- NULL
cl <- train$species
#creates function
my_knn_cv <- function(train, cl, k_nn, k_cv){
#randomly assigns observations to folds
train$fold <- sample(rep(1:k_cv, length = nrow(train)))
fold <- train$fold
#creates column to store prediction for all observations
class <- rep(NA, nrow(train))
#creates vector to store error calculations
misclass_rate <- rep(NA, k_cv)
#uses for loop to repeat steps for each fold
for (i in 1:k_cv) {
#creates train and test data
test_data <- train %>% filter(fold == i)
train_data <- train %>% filter(fold != i)
#creates vector of classes for both data sets
cl_train <- train_data$species
cl_test <- test_data$species
#removes class and fold columns from datasets
train_data <- train_data[ ,3:ncol(train_data)-1]
test_data <- test_data[ ,3:ncol(test_data)-1]
#stores predictions in dataset
class[train$fold == i] <- knn(train_data,
test_data,
cl_train,
k = k_nn,
prob = TRUE)
#creates vector to store misclassifications
error <- rep(NA, nrow(test_data))
#labels misclassifications
for (j in 1:nrow(test_data)) {
error[train$fold == j] =
(as.numeric(train$species[train$fold == j])) != class[train$fold == j]
}
#calculates misclassification rate
misclass_rate[i] <- sum(na.omit(as.numeric(error[train$fold == i])))
misclass_rate[i] <- misclass_rate[i] / length(cl_test)
}
#calculates mean misclassification rate
cv_err <- mean(misclass_rate)
#converts species to numeric
train$species <- as.numeric(train$species)
#generates output class
output_class <- knn(train, train, train$species, k = k_nn, prob = TRUE)
#creates list of objects to return
my_list <- list()
my_list$cv_err <- cv_err
my_list$class <- output_class
#returns list
return(my_list)
}
#tests function
my_knn_cv(train, cl, 1, 5)
knn_1 <- my_knn_cv(train, cl, 1, 5)
knn_5 <- my_knn_cv(train, cl, 5, 5)
training_err_1 <- mean((knn_1$class - as.numeric(train$species))^2)
training_err_5 <- mean((knn_5$class - as.numeric(train$species))^2)
my_data <- data.frame("k_nn" = c(1,5),
"Misclassification Error" = c(knn_1$cv_err, knn_5$cv_err),
"Training Error" = c(training_err_1, training_err_5))
library(knitr)
library(kableExtra)
kable_styling(kable(my_data))
mean((knn_1$class - as.numeric(penguins$species))^2)
penguins$species
as.numeric(penguins$sex)
as.numeric(penguins$species)
knn_1$class
knn(train, train, train$species, k = k_nn, prob = TRUE)
knn(train, train, train$species, k = 1, prob = TRUE)
train$species <- as.numeric(train$species)
knn(train, train, train$species, k = 1, prob = TRUE)
output_class <- knn(train, train, train$species, k = 1, prob = FALSE)
output_class
knn_1 <- my_knn_cv(train, cl, 1, 5)
mean((knn_1$class - as.numeric(penguins$species))^2)
knn_1$class
library(class)
library(tidyverse)
#removes observations with na values
penguins <- na.omit(penguins)
#removes unnecessary columns from dataset
train <- penguins
train$island <- NULL
train$sex <- NULL
train$year <- NULL
cl <- train$species
#creates function
my_knn_cv <- function(train, cl, k_nn, k_cv){
#randomly assigns observations to folds
train$fold <- sample(rep(1:k_cv, length = nrow(train)))
fold <- train$fold
#creates column to store prediction for all observations
class <- rep(NA, nrow(train))
#creates vector to store error calculations
misclass_rate <- rep(NA, k_cv)
#uses for loop to repeat steps for each fold
for (i in 1:k_cv) {
#creates train and test data
test_data <- train %>% filter(fold == i)
train_data <- train %>% filter(fold != i)
#creates vector of classes for both data sets
cl_train <- train_data$species
cl_test <- test_data$species
#removes class and fold columns from datasets
train_data <- train_data[ ,3:ncol(train_data)-1]
test_data <- test_data[ ,3:ncol(test_data)-1]
#stores predictions in dataset
class[train$fold == i] <- knn(train_data,
test_data,
cl_train,
k = k_nn,
prob = FALSE)
#creates vector to store misclassifications
error <- rep(NA, nrow(test_data))
#labels misclassifications
for (j in 1:nrow(test_data)) {
error[train$fold == j] =
(as.numeric(train$species[train$fold == j])) != class[train$fold == j]
}
#calculates misclassification rate
misclass_rate[i] <- sum(na.omit(as.numeric(error[train$fold == i])))
misclass_rate[i] <- misclass_rate[i] / length(cl_test)
}
#calculates mean misclassification rate
cv_err <- mean(misclass_rate)
#converts species to numeric
train$species <- as.numeric(train$species)
#generates output class
output_class <- knn(train, train, train$species, k = k_nn, prob = FALSE)
#creates list of objects to return
my_list <- list()
my_list$cv_err <- cv_err
my_list$class <- output_class
#returns list
return(my_list)
}
#tests function
my_knn_cv(train, cl, 1, 5)
knn_1 <- my_knn_cv(train, cl, 1, 5)
knn_5 <- my_knn_cv(train, cl, 5, 5)
training_err_1 <- mean((knn_1$class - as.numeric(penguins$species))^2)
training_err_5 <- mean((knn_5$class - as.numeric(train$species))^2)
my_data <- data.frame("k_nn" = c(1,5),
"Misclassification Error" = c(knn_1$cv_err, knn_5$cv_err),
"Training Error" = c(training_err_1, training_err_5))
library(knitr)
library(kableExtra)
kable_styling(kable(my_data))
library(class)
library(tidyverse)
#removes observations with na values
penguins <- na.omit(penguins)
#removes unnecessary columns from dataset
train <- penguins
train$island <- NULL
train$sex <- NULL
train$year <- NULL
cl <- train$species
train$fold <- sample(rep(1:k_cv, length = nrow(train)))
fold <- train$fold
train$fold <- sample(rep(1:k_cv, length = nrow(train)))
k_cv <- 5
k_nn <- 1
train$fold <- sample(rep(1:k_cv, length = nrow(train)))
fold <- train$fold
class <- rep(NA, nrow(train))
misclass_rate <- rep(NA, k_cv)
for (i in 1:k_cv) {
#creates train and test data
test_data <- train %>% filter(fold == i)
train_data <- train %>% filter(fold != i)
#creates vector of classes for both data sets
cl_train <- train_data$species
cl_test <- test_data$species
#removes class and fold columns from datasets
train_data <- train_data[ ,3:ncol(train_data)-1]
test_data <- test_data[ ,3:ncol(test_data)-1]
#stores predictions in dataset
class[train$fold == i] <- knn(train_data,
test_data,
cl_train,
k = k_nn,
prob = FALSE)
#creates vector to store misclassifications
error <- rep(NA, nrow(test_data))
#labels misclassifications
for (j in 1:nrow(test_data)) {
error[train$fold == j] =
(as.numeric(train$species[train$fold == j])) != class[train$fold == j]
}
my_knn_cv(train, cl, 1, 5)
knn_1 <- my_knn_cv(train, cl, 1, 5)
knn_1$class
mean((as.numeric(knn_1$class) - as.numeric(penguins$species))^2)
library(class)
library(tidyverse)
#removes observations with na values
penguins <- na.omit(penguins)
#removes unnecessary columns from dataset
train <- penguins
train$island <- NULL
train$sex <- NULL
train$year <- NULL
cl <- train$species
#creates function
my_knn_cv <- function(train, cl, k_nn, k_cv){
#randomly assigns observations to folds
train$fold <- sample(rep(1:k_cv, length = nrow(train)))
fold <- train$fold
#creates column to store prediction for all observations
class <- rep(NA, nrow(train))
#creates vector to store error calculations
misclass_rate <- rep(NA, k_cv)
#uses for loop to repeat steps for each fold
for (i in 1:k_cv) {
#creates train and test data
test_data <- train %>% filter(fold == i)
train_data <- train %>% filter(fold != i)
#creates vector of classes for both data sets
cl_train <- train_data$species
cl_test <- test_data$species
#removes class and fold columns from datasets
train_data <- train_data[ ,3:ncol(train_data)-1]
test_data <- test_data[ ,3:ncol(test_data)-1]
#stores predictions in dataset
class[train$fold == i] <- knn(train_data,
test_data,
cl_train,
k = k_nn,
prob = FALSE)
#creates vector to store misclassifications
error <- rep(NA, nrow(test_data))
#labels misclassifications
for (j in 1:nrow(test_data)) {
error[train$fold == j] =
(as.numeric(train$species[train$fold == j])) != class[train$fold == j]
}
#calculates misclassification rate
misclass_rate[i] <- sum(na.omit(as.numeric(error[train$fold == i])))
misclass_rate[i] <- misclass_rate[i] / length(cl_test)
}
#calculates mean misclassification rate
cv_err <- mean(misclass_rate)
#converts species to numeric
train$species <- as.numeric(train$species)
#generates output class
output_class <- knn(train, train, train$species, k = k_nn, prob = FALSE)
#creates list of objects to return
my_list <- list()
my_list$cv_err <- cv_err
my_list$class <- output_class
#returns list
return(my_list)
}
#tests function
my_knn_cv(train, cl, 1, 5)
knn_1 <- my_knn_cv(train, cl, 1, 5)
knn_5 <- my_knn_cv(train, cl, 5, 5)
training_err_1 <- mean((as.numeric(knn_1$class) - as.numeric(penguins$species))^2)
training_err_5 <- mean((as.numeric(knn_5$class) - as.numeric(train$species))^2)
my_data <- data.frame("k_nn" = c(1,5),
"Misclassification Error" = c(knn_1$cv_err, knn_5$cv_err),
"Training Error" = c(training_err_1, training_err_5))
library(knitr)
library(kableExtra)
kable_styling(kable(my_data))
#removes observations with na values
train <- na.omit(my_penguins)
#removes unnecessary columns from dataset
train$island <- NULL
train$sex <- NULL
train$year <- NULL
cl <- train$species
#creates vectors to store training and cv misclassification errors
train_err <- rep(NA, 10)
cv_misclass_err <- rep(NA, 10)
#tests function, iterating with k_nn values from 1 to 10
for (i in 1:10) {
knn_i <- my_knn_cv(train, cl, i, 5)
cv_misclass_err[i] <- knn_i$cv_err
#calculates training error
train_err[i] <- mean((as.numeric(knn_i$class) - as.numeric(train$species))^2)
}
my_df <- data.frame("k_nn" = c(1:10),
"CV Misclassification Error" = cv_misclass_err,
"Training Error" = train_err)
kable_styling(kable(my_df))
#removes observations with na values
train <- na.omit(my_penguins)
#removes unnecessary columns from dataset
train$island <- NULL
train$sex <- NULL
train$year <- NULL
cl <- train$species
#creates vectors to store training and cv misclassification errors
train_err <- rep(NA, 10)
cv_misclass_err <- rep(NA, 10)
#tests function, iterating with k_nn values from 1 to 10
for (i in 1:10) {
knn_i <- my_knn_cv(train, cl, i, 5)
cv_misclass_err[i] <- knn_i$cv_err
#calculates training error
train_err[i] <- mean((as.numeric(knn_i$class) - as.numeric(train$species))^2)
}
my_df <- data.frame("k_nn" = c(1:10),
"CV Misclassification Error" = cv_misclass_err,
"Training Error" = train_err)
kable_styling(kable(my_df))
devtools::document()
devtools::document()
#removes observations with na values
train <- na.omit(my_penguins)
#removes unnecessary columns from dataset
train$island <- NULL
train$sex <- NULL
train$year <- NULL
cl <- train$species
#creates vectors to store training and cv misclassification errors
train_err <- rep(NA, 10)
cv_misclass_err <- rep(NA, 10)
#tests function, iterating with k_nn values from 1 to 10
for (i in 1:10) {
knn_i <- my_knn_cv(train, cl, i, 5)
cv_misclass_err[i] <- knn_i$cv_err
#calculates training error
train_err[i] <- mean((as.numeric(knn_i$class) - as.numeric(train$species))^2)
}
my_df <- data.frame("k_nn" = c(1:10),
"CV Misclassification Error" = cv_misclass_err,
"Training Error" = train_err)
kable_styling(kable(my_df))
train <- na.omit(my_penguins)
train$island <- NULL
train$sex <- NULL
train$year <- NULL
cl <- train$species
train_err <- rep(NA, 10)
cv_misclass_err <- rep(NA, 10)
for (i in 1:10) {
knn_i <- my_knn_cv(train, cl, i, 5)
cv_misclass_err[i] <- knn_i$cv_err
#calculates training error
train_err[i] <- mean((as.numeric(knn_i$class) - as.numeric(train$species))^2)
}
knn_1 <- my_knn_cv(train, cl, 1, 5)
cv_misclass_err[1] <- knn_1$cv_err
train_err[1] <- mean((as.numeric(knn_1$class) - as.numeric(train$species))^2)
#removes observations with na values
train <- na.omit(my_penguins)
#removes unnecessary columns from dataset
train$island <- NULL
train$sex <- NULL
train$year <- NULL
cl <- train$species
#creates vectors to store training and cv misclassification errors
train_err <- rep(NA, 10)
cv_misclass_err <- rep(NA, 10)
#tests function, iterating with k_nn values from 1 to 10
for (i in 1:10) {
knn_i <- my_knn_cv(train, cl, i, 5)
cv_misclass_err[i] <- knn_i$cv_err
#calculates training error
train_err[i] <- mean((as.numeric(knn_i$class) - as.numeric(train$species))^2)
}
my_df <- data.frame("k_nn" = c(1:10),
"CV Misclassification Error" = cv_misclass_err,
"Training Error" = train_err)
kable_styling(kable(my_df))
devtools::check()
